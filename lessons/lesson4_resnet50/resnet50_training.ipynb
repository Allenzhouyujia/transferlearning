{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lesson 4: ResNet50 Transfer Learning for Flower Classification\n",
        "\n",
        "## Overview\n",
        "Learn transfer learning with ResNet50 on the Flowers102 dataset. This lesson demonstrates how pre-trained models can be adapted for new classification tasks with improved accuracy compared to ResNet18.\n",
        "\n",
        "### Learning Objectives\n",
        "- Understand ResNet50 architecture and deeper residual networks\n",
        "- Implement transfer learning with pre-trained weights\n",
        "- Use progressive training strategy (freeze ‚Üí fine-tune)\n",
        "- Compare performance with ResNet18 and analyze results\n",
        "\n",
        "### ResNet50 vs ResNet18 Comparison\n",
        "- **Depth**: ResNet50 has 50 layers vs ResNet18's 18 layers\n",
        "- **Parameters**: ResNet50 has 25.6M parameters vs ResNet18's 11.7M parameters\n",
        "- **Block Structure**: ResNet50 uses bottleneck blocks (1√ó1, 3√ó3, 1√ó1 convolutions) while ResNet18 uses basic blocks (two 3√ó3 convolutions)\n",
        "- **Complexity**: ResNet50 is more computationally intensive but captures more complex features\n",
        "- **Accuracy**: ResNet50 typically achieves higher accuracy on complex tasks due to its deeper architecture\n",
        "- **Training Time**: ResNet50 requires more time and resources to train compared to ResNet18\n",
        "\n",
        "### ResNet50 Advantages and Disadvantages\n",
        "- **Advantages**:\n",
        "  - Deeper network structure (50 layers) captures more complex features\n",
        "  - Bottleneck design improves parameter efficiency\n",
        "  - Excellent transfer learning performance with pre-trained models\n",
        "  - Higher accuracy on complex classification tasks\n",
        "- **Disadvantages**:\n",
        "  - Large parameter count (25.6M) requires more storage\n",
        "  - Higher computational resource demands, slower training and inference\n",
        "  - Potentially over-complex for simple tasks with limited performance gains\n",
        "  - More prone to overfitting on small datasets, requires stronger regularization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Environment Setup and Library Imports\n",
        "\n",
        "### Key Libraries:\n",
        "- **torch**: Core PyTorch library (tensors, automatic differentiation, neural networks)\n",
        "- **torchvision**: Computer vision utilities (datasets, transforms, pre-trained models)\n",
        "- **models**: Pre-trained model architectures (ResNet50, etc.)\n",
        "- **optim**: Optimization algorithms (SGD, Adam, AdamW)\n",
        "- **DataLoader**: Efficient batch processing and parallel data loading\n",
        "- **tqdm**: Progress bars for training loops\n",
        "- **matplotlib**: Data visualization and plotting\n",
        "- **sklearn**: Machine learning utilities (metrics, confusion matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully!\n",
            "üì¶ PyTorch version: 2.2.2\n",
            "üñºÔ∏è Torchvision version: 0.17.2\n",
            "üî• CUDA available: False\n",
            "üçé MPS available: True\n"
          ]
        }
      ],
      "source": [
        "# Core PyTorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Computer vision utilities\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "\n",
        "# Data handling and visualization\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# Machine learning utilities\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure matplotlib for high-quality plots\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.style.use('default')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"üì¶ PyTorch version: {torch.__version__}\")\n",
        "print(f\"üñºÔ∏è Torchvision version: {torchvision.__version__}\")\n",
        "print(f\"üî• CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"üçé MPS available: {torch.backends.mps.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Device Detection and Configuration\n",
        "\n",
        "### Device Selection Strategy\n",
        "ResNet50 requires more computational resources than ResNet18. Our device detection follows this priority:\n",
        "\n",
        "1. **CUDA GPU** (NVIDIA): Highly recommended for ResNet50 training\n",
        "   - Parallel processing with thousands of cores\n",
        "   - Large memory capacity for deep networks\n",
        "   - Optimized for matrix operations\n",
        "\n",
        "2. **MPS (Apple Silicon)**: Apple's Metal Performance Shaders\n",
        "   - Efficient on M1/M2 chips\n",
        "   - May need batch size reduction for memory constraints\n",
        "   - Good performance for development\n",
        "\n",
        "3. **CPU**: Not recommended for ResNet50\n",
        "   - Very slow training (hours instead of minutes)\n",
        "   - Use only for testing/debugging\n",
        "\n",
        "### Training Configuration\n",
        "We use the same parameters as ResNet18 for fair comparison:\n",
        "- **Batch Size**: 32 (may need reduction to 16 for memory limits)\n",
        "- **Learning Rate**: 0.001 (standard for AdamW optimizer)\n",
        "- **Epochs**: 50 total (20 frozen + 30 fine-tuning)\n",
        "- **Optimizer**: AdamW with weight decay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Detecting optimal compute device...\n",
            "üçé Using Apple Silicon GPU (MPS)\n",
            "   Optimized for M1/M2 chips\n",
            "   ‚ö†Ô∏è  May need batch size reduction for ResNet50\n",
            "\n",
            "‚öôÔ∏è Setting up training configuration...\n",
            "   üì¶ Batch size: 32 (reduce to 16 if memory issues)\n",
            "   üéØ Learning rate: 0.003\n",
            "   üîÑ Total epochs: 50 (freeze: 20, fine-tune: 30)\n",
            "   üë• Workers: 0\n",
            "   ‚öñÔ∏è Weight decay: 0.01\n",
            "\n",
            "‚úÖ Configuration complete!\n",
            "üí° If you encounter memory issues, reduce batch_size to 16 or 8\n"
          ]
        }
      ],
      "source": [
        "# Device detection with fallback hierarchy\n",
        "print(\"üîç Detecting optimal compute device...\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"üöÄ Using NVIDIA GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(f\"   üí° ResNet50 recommended: Good memory for deep network\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"üçé Using Apple Silicon GPU (MPS)\")\n",
        "    print(\"   Optimized for M1/M2 chips\")\n",
        "    print(\"   ‚ö†Ô∏è  May need batch size reduction for ResNet50\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"üíª Using CPU\")\n",
        "    print(\"   ‚ö†Ô∏è  NOT recommended for ResNet50 - very slow training\")\n",
        "\n",
        "# Set training configuration\n",
        "print(\"\\n‚öôÔ∏è Setting up training configuration...\")\n",
        "config = {\n",
        "    'batch_size': 32,  # May need reduction for memory limits\n",
        "    'learning_rate': 0.003,\n",
        "    'epochs': 50,\n",
        "    'freeze_epochs': 20,\n",
        "    'finetune_epochs': 30,\n",
        "    'num_workers': 0,\n",
        "    'weight_decay': 0.01\n",
        "}\n",
        "\n",
        "print(f\"   üì¶ Batch size: {config['batch_size']} (reduce to 16 if memory issues)\")\n",
        "print(f\"   üéØ Learning rate: {config['learning_rate']}\")\n",
        "print(f\"   üîÑ Total epochs: {config['epochs']} (freeze: {config['freeze_epochs']}, fine-tune: {config['finetune_epochs']})\")\n",
        "print(f\"   üë• Workers: {config['num_workers']}\")\n",
        "print(f\"   ‚öñÔ∏è Weight decay: {config['weight_decay']}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "print(\"\\n‚úÖ Configuration complete!\")\n",
        "print(\"üí° If you encounter memory issues, reduce batch_size to 16 or 8\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Data Preprocessing and DataLoader Setup\n",
        "\n",
        "### Data Augmentation Strategy\n",
        "\n",
        "**Why Augmentation is Critical for ResNet50:**\n",
        "- **Prevents Overfitting**: Deeper networks are more prone to overfitting\n",
        "- **Increases Effective Dataset Size**: More parameters need more data variations\n",
        "- **Improves Generalization**: Helps the model handle real-world variations\n",
        "- **Maximizes Transfer Learning**: Augmentation helps adaptation to new domain\n",
        "\n",
        "**Training vs. Validation Transforms:**\n",
        "- **Training**: Aggressive augmentation for robustness\n",
        "- **Validation/Test**: Minimal transforms for consistent evaluation\n",
        "\n",
        "### ImageNet Normalization\n",
        "Critical for pre-trained models - ResNet50 expects exact ImageNet statistics:\n",
        "- **Mean**: [0.485, 0.456, 0.406] for RGB channels\n",
        "- **Std**: [0.229, 0.224, 0.225] for RGB channels\n",
        "\n",
        "### Memory Considerations\n",
        "ResNet50 uses more memory than ResNet18:\n",
        "- **Batch Size**: May need reduction from 32 to 16 or 8\n",
        "- **Workers**: Monitor CPU usage during data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Creating data preprocessing pipeline...\n",
            "   ‚úì Training transforms: 5 augmentations + ImageNet normalization\n",
            "   ‚úì Validation transforms: resize + ImageNet normalization only\n",
            "\n",
            "üì¶ Loading Flowers102 dataset...\n",
            "   üèãÔ∏è Training samples: 1,020\n",
            "   üîç Validation samples: 1,020\n",
            "   üìù Test samples: 6,149\n",
            "\n",
            "‚öôÔ∏è Setting up DataLoaders...\n",
            "   üìä DataLoader batches: 32 train, 32 val, 193 test\n",
            "   ‚úÖ Data pipeline ready!\n"
          ]
        }
      ],
      "source": [
        "print(\"üîß Creating data preprocessing pipeline...\")\n",
        "\n",
        "# Training transforms with augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Validation transforms (no augmentation)\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"   ‚úì Training transforms: 5 augmentations + ImageNet normalization\")\n",
        "print(\"   ‚úì Validation transforms: resize + ImageNet normalization only\")\n",
        "\n",
        "# Create datasets\n",
        "print(\"\\nüì¶ Loading Flowers102 dataset...\")\n",
        "try:\n",
        "    train_dataset = torchvision.datasets.Flowers102(\n",
        "        root='./data', split='train', transform=train_transforms, download=True)\n",
        "    val_dataset = torchvision.datasets.Flowers102(\n",
        "        root='./data', split='val', transform=val_transforms, download=True)\n",
        "    test_dataset = torchvision.datasets.Flowers102(\n",
        "        root='./data', split='test', transform=val_transforms, download=True)\n",
        "    \n",
        "    print(f\"   üèãÔ∏è Training samples: {len(train_dataset):,}\")\n",
        "    print(f\"   üîç Validation samples: {len(val_dataset):,}\")\n",
        "    print(f\"   üìù Test samples: {len(test_dataset):,}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Error loading dataset: {e}\")\n",
        "    print(\"   üí° Make sure you have internet connection for first download\")\n",
        "\n",
        "# Create DataLoaders with memory monitoring\n",
        "print(\"\\n‚öôÔ∏è Setting up DataLoaders...\")\n",
        "try:\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], \n",
        "                             shuffle=True, num_workers=config['num_workers'], pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], \n",
        "                           shuffle=False, num_workers=config['num_workers'], pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], \n",
        "                            shuffle=False, num_workers=config['num_workers'], pin_memory=True)\n",
        "    \n",
        "    print(f\"   üìä DataLoader batches: {len(train_loader)} train, {len(val_loader)} val, {len(test_loader)} test\")\n",
        "    print(\"   ‚úÖ Data pipeline ready!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Error creating DataLoaders: {e}\")\n",
        "    print(\"   üí° Try reducing batch_size or num_workers\")\n",
        "    print(\"   üí° Suggested fix: config['batch_size'] = 16\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 4: ResNet50 Model Setup and Architecture Analysis\n",
        "\n",
        "### ResNet50 vs ResNet18 Comparison\n",
        "\n",
        "| Feature | ResNet18 | ResNet50 | Impact |\n",
        "|---------|----------|----------|---------|\n",
        "| **Layers** | 18 | 50 | 2.8√ó deeper |\n",
        "| **Parameters** | 11.7M | 25.6M | 2.2√ó more |\n",
        "| **Model Size** | ~47MB | ~102MB | 2.2√ó larger |\n",
        "| **Memory Usage** | ~2GB | ~3-4GB | 1.5-2√ó more |\n",
        "| **Training Time** | 15-20 min | 25-35 min | 1.5-2√ó slower |\n",
        "\n",
        "### Bottleneck Block Innovation\n",
        "ResNet50 uses bottleneck blocks instead of basic blocks:\n",
        "- **1√ó1 Conv**: Reduces channels for efficiency\n",
        "- **3√ó3 Conv**: Processes features with reduced channels\n",
        "- **1√ó1 Conv**: Expands channels back to original size\n",
        "- **Skip Connection**: Enables deep network training\n",
        "\n",
        "### Transfer Learning Advantages\n",
        "ResNet50's depth provides:\n",
        "- **Richer Feature Hierarchy**: More complex pattern recognition\n",
        "- **Better Generalization**: Proven performance on diverse tasks\n",
        "- **Stable Training**: Residual connections prevent vanishing gradients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèóÔ∏è Setting up ResNet50 model...\n",
            "   ‚úì Loaded pre-trained ResNet50\n",
            "   üìä Original final layer: 2048 ‚Üí 1000 classes\n",
            "   üéØ Modified final layer: 2048 ‚Üí 102 classes\n",
            "   üöÄ Model moved to mps\n",
            "   üìà Total parameters: 23,717,030\n",
            "   üéØ Trainable parameters: 23,717,030\n",
            "   üìä Model size: 94.9 MB (float32)\n",
            "\n",
            "üìä ResNet50 vs ResNet18 comparison:\n",
            "   üìà Parameter ratio: 2.0√ó more parameters\n",
            "   üíæ Memory ratio: 2.0√ó more memory\n",
            "\n",
            "‚öôÔ∏è Training setup:\n",
            "   üéØ Loss function: CrossEntropyLoss\n",
            "   üöÄ Optimizer: AdamW (lr=0.003, weight_decay=0.01)\n",
            "‚úÖ ResNet50 model setup complete!\n",
            "üí° Ready for two-phase training: feature extraction ‚Üí fine-tuning\n"
          ]
        }
      ],
      "source": [
        "print(\"üèóÔ∏è Setting up ResNet50 model...\")\n",
        "\n",
        "# Load pre-trained ResNet50\n",
        "model = models.resnet50(pretrained=True)\n",
        "print(f\"   ‚úì Loaded pre-trained ResNet50\")\n",
        "print(f\"   üìä Original final layer: {model.fc.in_features} ‚Üí 1000 classes\")\n",
        "\n",
        "# Modify final layer for Flowers102 (102 classes)\n",
        "num_classes = 102\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "print(f\"   üéØ Modified final layer: {model.fc.in_features} ‚Üí {num_classes} classes\")\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "print(f\"   üöÄ Model moved to {device}\")\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"   üìà Total parameters: {total_params:,}\")\n",
        "print(f\"   üéØ Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   üìä Model size: {total_params * 4 / 1e6:.1f} MB (float32)\")\n",
        "\n",
        "# Compare with ResNet18\n",
        "resnet18_params = 11_689_512  # Known ResNet18 parameter count\n",
        "print(f\"\\nüìä ResNet50 vs ResNet18 comparison:\")\n",
        "print(f\"   üìà Parameter ratio: {total_params / resnet18_params:.1f}√ó more parameters\")\n",
        "print(f\"   üíæ Memory ratio: {total_params / resnet18_params:.1f}√ó more memory\")\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è Training setup:\")\n",
        "print(f\"   üéØ Loss function: CrossEntropyLoss\")\n",
        "print(f\"   üöÄ Optimizer: AdamW (lr={config['learning_rate']}, weight_decay={config['weight_decay']})\")\n",
        "\n",
        "# Function to freeze/unfreeze model parameters\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        # Only train the classifier\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "    else:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "print(\"‚úÖ ResNet50 model setup complete!\")\n",
        "print(\"üí° Ready for two-phase training: feature extraction ‚Üí fine-tuning\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 5: Training and Evaluation Functions\n",
        "\n",
        "### Function Design for Deep Networks\n",
        "Our training functions are optimized for deeper networks like ResNet50:\n",
        "- **Memory Management**: Efficient GPU memory usage\n",
        "- **Progress Monitoring**: Real-time loss and accuracy tracking\n",
        "- **Error Handling**: Graceful handling of memory issues\n",
        "- **Performance Metrics**: Comprehensive evaluation\n",
        "\n",
        "### Training Strategy\n",
        "We use the same two-phase approach as ResNet18 for fair comparison:\n",
        "1. **Phase 1**: Feature extraction (frozen backbone)\n",
        "2. **Phase 2**: End-to-end fine-tuning (unfrozen network)\n",
        "\n",
        "### Memory Optimization\n",
        "The functions include automatic memory cleanup to handle ResNet50's higher memory usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Training and evaluation functions defined!\n",
            "üí° Functions include memory optimization for ResNet50\n"
          ]
        }
      ],
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"Train model for one epoch with memory optimization\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "    \n",
        "    for batch_idx, (data, targets) in enumerate(progress_bar):\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'Loss': f'{running_loss/(batch_idx+1):.3f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "        \n",
        "        # Memory cleanup for ResNet50\n",
        "        del data, targets, outputs, loss\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "    \n",
        "    return running_loss / len(train_loader), 100. * correct / total\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    \"\"\"Evaluate model on validation set with memory optimization\"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(val_loader, desc=\"Evaluating\", leave=False)\n",
        "        \n",
        "        for batch_idx, (data, targets) in enumerate(progress_bar):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)\n",
        "            \n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            \n",
        "            progress_bar.set_postfix({\n",
        "                'Loss': f'{val_loss/(batch_idx+1):.3f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "            \n",
        "            # Memory cleanup for ResNet50\n",
        "            del data, targets, outputs, loss\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "    \n",
        "    return val_loss / len(val_loader), 100. * correct / total\n",
        "\n",
        "print(\"‚úÖ Training and evaluation functions defined!\")\n",
        "print(\"üí° Functions include memory optimization for ResNet50\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### ResNet50 Architecture Overview for Phase 1\n",
        "\n",
        "ResNet50 consists of:\n",
        "- Initial Layers: Conv2d, BatchNorm, MaxPool\n",
        "- 4 Layer Groups: Each with multiple bottleneck blocks\n",
        "  - Layer1: 3 bottleneck blocks (64-256 channels)\n",
        "  - Layer2: 4 bottleneck blocks (128-512 channels)\n",
        "  - Layer3: 6 bottleneck blocks (256-1024 channels)\n",
        "  - Layer4: 3 bottleneck blocks (512-2048 channels)\n",
        "- Final Classifier: Adaptive AvgPool + Linear layer (2048‚Üí102 classes)\n",
        "\n",
        "In Phase 1, we're freezing all convolutional layers (the entire backbone) and only training the final classifier layer. This approach leverages ResNet50's deep feature extraction capabilities while adapting only the decision boundary to our flower dataset.\n",
        "\n",
        "### Why This Works Well for ResNet50\n",
        "- Pre-trained Features: 50 layers of ImageNet features are very rich\n",
        "- Computational Efficiency: Only training ~100K parameters vs 25.6M\n",
        "- Memory Efficiency: Lower memory usage during backpropagation\n",
        "- Stable Learning: Avoids disturbing learned features initially\n",
        "\n",
        "### Expected Performance\n",
        "- ResNet18: ~75% accuracy after Phase 1\n",
        "- ResNet50: ~78% accuracy after Phase 1 (3% improvement)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Phase 1: Feature Extraction Training (ResNet50)\n",
            "============================================================\n",
            "   üîí Frozen parameters: 23,508,032 (99.1%)\n",
            "   üéØ Trainable parameters: 208,998 (0.9%)\n",
            "   üìä Training efficiency: 112√ó fewer parameters to train\n",
            "\n",
            "üöÄ Starting Phase 1 training (20 epochs)...\n",
            "üí° This may take longer than ResNet18 due to deeper network\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  1/20 | Train Loss: 5.4296 | Train Acc: 8.14% | Val Loss: 2.9884 | Val Acc: 38.53% | Time: 23.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  2/20 | Train Loss: 2.2060 | Train Acc: 51.27% | Val Loss: 1.9253 | Val Acc: 55.49% | Time: 22.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  3/20 | Train Loss: 1.3405 | Train Acc: 69.22% | Val Loss: 1.4581 | Val Acc: 66.37% | Time: 22.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  4/20 | Train Loss: 0.9172 | Train Acc: 78.92% | Val Loss: 1.3252 | Val Acc: 68.73% | Time: 22.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  5/20 | Train Loss: 0.7106 | Train Acc: 82.84% | Val Loss: 1.0860 | Val Acc: 72.94% | Time: 23.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  6/20 | Train Loss: 0.5008 | Train Acc: 88.24% | Val Loss: 0.9949 | Val Acc: 74.41% | Time: 22.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  7/20 | Train Loss: 0.3985 | Train Acc: 90.59% | Val Loss: 0.9794 | Val Acc: 73.82% | Time: 21.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  8/20 | Train Loss: 0.4070 | Train Acc: 90.88% | Val Loss: 0.9947 | Val Acc: 74.90% | Time: 22.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  9/20 | Train Loss: 0.3587 | Train Acc: 91.47% | Val Loss: 0.8867 | Val Acc: 77.16% | Time: 22.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/20 | Train Loss: 0.3352 | Train Acc: 92.06% | Val Loss: 0.9415 | Val Acc: 76.86% | Time: 22.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/20 | Train Loss: 0.3029 | Train Acc: 92.25% | Val Loss: 0.9208 | Val Acc: 75.78% | Time: 22.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/20 | Train Loss: 0.2505 | Train Acc: 93.82% | Val Loss: 1.0038 | Val Acc: 75.20% | Time: 24.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/20 | Train Loss: 0.2681 | Train Acc: 92.75% | Val Loss: 0.8017 | Val Acc: 79.41% | Time: 22.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/20 | Train Loss: 0.2374 | Train Acc: 93.73% | Val Loss: 0.9523 | Val Acc: 75.20% | Time: 23.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/20 | Train Loss: 0.2079 | Train Acc: 95.10% | Val Loss: 0.8657 | Val Acc: 77.35% | Time: 21.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/20 | Train Loss: 0.2490 | Train Acc: 93.63% | Val Loss: 0.9025 | Val Acc: 76.67% | Time: 21.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/20 | Train Loss: 0.2041 | Train Acc: 94.51% | Val Loss: 0.9009 | Val Acc: 78.73% | Time: 21.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/20 | Train Loss: 0.1658 | Train Acc: 95.69% | Val Loss: 0.9072 | Val Acc: 76.86% | Time: 21.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/20 | Train Loss: 0.1895 | Train Acc: 95.10% | Val Loss: 0.9981 | Val Acc: 75.69% | Time: 21.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/20 | Train Loss: 0.1614 | Train Acc: 94.71% | Val Loss: 0.8385 | Val Acc: 79.41% | Time: 21.6s\n",
            "\n",
            "üìä Phase 1 Results:\n",
            "   ‚è±Ô∏è  Training time: 446.9s (7.4m)\n",
            "   üéØ Best validation accuracy: 79.41%\n",
            "   üìà Final training accuracy: 94.71%\n",
            "   üìâ Final validation loss: 0.8385\n",
            "\n",
            "üîç Comparison with ResNet18:\n",
            "   üìä ResNet18 Phase 1: 78.43%\n",
            "   üìä ResNet50 Phase 1: 79.41%\n",
            "   üöÄ Improvement: +1.0% (deeper network advantage)\n",
            "‚úÖ Phase 1 complete! Best model weights loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(\"üéØ Phase 1: Feature Extraction Training (ResNet50)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Freeze backbone, only train classifier\n",
        "set_parameter_requires_grad(model, feature_extracting=True)\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "frozen_params = total_params - trainable_params\n",
        "\n",
        "print(f\"   üîí Frozen parameters: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)\")\n",
        "print(f\"   üéØ Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
        "print(f\"   üìä Training efficiency: {frozen_params/trainable_params:.0f}√ó fewer parameters to train\")\n",
        "\n",
        "# Training tracking\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "print(f\"\\nüöÄ Starting Phase 1 training ({config['freeze_epochs']} epochs)...\")\n",
        "print(\"üí° This may take longer than ResNet18 due to deeper network\")\n",
        "phase1_start = time.time()\n",
        "\n",
        "best_val_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "try:\n",
        "    for epoch in range(config['freeze_epochs']):\n",
        "        epoch_start = time.time()\n",
        "        \n",
        "        # Training\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        \n",
        "        # Validation\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "        # Record metrics\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "        \n",
        "        epoch_time = time.time() - epoch_start\n",
        "        \n",
        "        print(f\"Epoch {epoch+1:2d}/{config['freeze_epochs']} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | \"\n",
        "              f\"Time: {epoch_time:.1f}s\")\n",
        "        \n",
        "        # Memory monitoring\n",
        "        if torch.cuda.is_available():\n",
        "            memory_used = torch.cuda.memory_allocated() / 1e9\n",
        "            if memory_used > 0.5:  # Show if using > 0.5GB\n",
        "                print(f\"           GPU Memory: {memory_used:.1f}GB\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Training error: {e}\")\n",
        "    print(\"üí° Try reducing batch_size in config if memory error\")\n",
        "\n",
        "phase1_time = time.time() - phase1_start\n",
        "\n",
        "print(f\"\\nüìä Phase 1 Results:\")\n",
        "print(f\"   ‚è±Ô∏è  Training time: {phase1_time:.1f}s ({phase1_time/60:.1f}m)\")\n",
        "print(f\"   üéØ Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"   üìà Final training accuracy: {train_accuracies[-1]:.2f}%\")\n",
        "print(f\"   üìâ Final validation loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# ResNet18 comparison (expected values)\n",
        "resnet18_phase1_acc = 78.43  # Based on actual ResNet18 Phase 1 results\n",
        "improvement = best_val_acc - resnet18_phase1_acc\n",
        "print(f\"\\nüîç Comparison with ResNet18:\")\n",
        "print(f\"   üìä ResNet18 Phase 1: {resnet18_phase1_acc:.2f}%\")\n",
        "print(f\"   üìä ResNet50 Phase 1: {best_val_acc:.2f}%\")\n",
        "print(f\"   üöÄ Improvement: {improvement:+.1f}% (deeper network advantage)\")\n",
        "\n",
        "# Load best model weights\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(\"‚úÖ Phase 1 complete! Best model weights loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 7: Phase 2 - Fine-tuning Training\n",
        "\n",
        "### Understanding Fine-tuning in ResNet50\n",
        "In this phase, we unlock and train all layers of the ResNet50 network to fully adapt it to our flower classification task.\n",
        "\n",
        "**Key Benefits of ResNet50 Fine-tuning:**\n",
        "- **Layer-by-Layer Adaptation**: \n",
        "  - Early layers learn basic flower patterns\n",
        "  - Middle layers capture complex textures\n",
        "  - Deep layers specialize in flower categories\n",
        "- **Stable Learning**: Skip connections prevent vanishing gradients\n",
        "- **Enhanced Accuracy**: Deeper architecture captures more nuanced features\n",
        "\n",
        "### Performance Expectations\n",
        "| Model     | Phase 2 Accuracy | Improvement |\n",
        "|-----------|------------------|-------------|\n",
        "| ResNet18  | ~85%             | Baseline    |\n",
        "| ResNet50  | ~88%             | +3%         |\n",
        "\n",
        "### Training Specifications\n",
        "- **Parameters**: All 25.6 million parameters trainable\n",
        "- **Memory**: Requires 3-4GB GPU memory (50% more than ResNet18)\n",
        "- **Speed**: Slower training due to full network updates\n",
        "- **Learning Rate**: Maintained at 0.001 for consistency\n",
        "\n",
        "### Memory Optimization Tips\n",
        "1. **GPU Monitoring**: Watch memory usage during training\n",
        "2. **Batch Size Adjustment**: Reduce if memory errors occur\n",
        "3. **Gradient Management**: Automatic cleanup prevents memory leaks\n",
        "4. **Efficient Training**: Use mixed precision if supported\n",
        "\n",
        "**Pro Tip:** If encountering memory issues, try:\n",
        "- Reducing batch size\n",
        "- Using gradient checkpointing\n",
        "- Enabling mixed precision training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî• Phase 2: Fine-tuning Training (ResNet50)\n",
            "============================================================\n",
            "   üîì All parameters unfrozen\n",
            "   üéØ Trainable parameters: 23,717,030 (100% of network)\n",
            "   üìä Full network training: 23.7M parameters\n",
            "\n",
            "‚öôÔ∏è Enhanced Configuration:\n",
            "   üéØ Learning rate: 0.0001 (reduced for fine-tuning)\n",
            "   üìÖ Scheduler: StepLR (step_size=10, gamma=0.5)\n",
            "   üõë Early stopping: patience=8, min_delta=0.001\n",
            "   üíæ Model save path: ./models/resnet50_flowers102_best.pth\n",
            "\n",
            "üöÄ Starting Phase 2 training (30 epochs)...\n",
            "üí° Fine-tuning will take longer than Phase 1 (full network backprop)\n",
            "üí° Memory usage will be higher - monitor for potential issues\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 81.96%\n",
            "Epoch  1/30 | Train Loss: 0.1399 | Train Acc: 96.86% | Val Loss: 0.6996 | Val Acc: 81.96% | LR: 0.000100 | Time: 37.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 84.02%\n",
            "Epoch  2/30 | Train Loss: 0.1206 | Train Acc: 96.37% | Val Loss: 0.6278 | Val Acc: 84.02% | LR: 0.000100 | Time: 33.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 86.37%\n",
            "Epoch  3/30 | Train Loss: 0.0676 | Train Acc: 98.43% | Val Loss: 0.5826 | Val Acc: 86.37% | LR: 0.000100 | Time: 33.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  4/30 | Train Loss: 0.0596 | Train Acc: 98.33% | Val Loss: 0.5799 | Val Acc: 85.00% | LR: 0.000100 | Time: 32.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  5/30 | Train Loss: 0.0372 | Train Acc: 99.31% | Val Loss: 0.5552 | Val Acc: 85.59% | LR: 0.000100 | Time: 32.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 87.16%\n",
            "Epoch  6/30 | Train Loss: 0.0239 | Train Acc: 99.51% | Val Loss: 0.5372 | Val Acc: 87.16% | LR: 0.000100 | Time: 33.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 87.65%\n",
            "Epoch  7/30 | Train Loss: 0.0160 | Train Acc: 99.80% | Val Loss: 0.4702 | Val Acc: 87.65% | LR: 0.000100 | Time: 33.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 87.84%\n",
            "Epoch  8/30 | Train Loss: 0.0152 | Train Acc: 99.51% | Val Loss: 0.4818 | Val Acc: 87.84% | LR: 0.000100 | Time: 33.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  9/30 | Train Loss: 0.0359 | Train Acc: 99.12% | Val Loss: 0.5122 | Val Acc: 87.35% | LR: 0.000100 | Time: 32.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/30 | Train Loss: 0.0191 | Train Acc: 99.71% | Val Loss: 0.5003 | Val Acc: 87.16% | LR: 0.000050 | Time: 32.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/30 | Train Loss: 0.0160 | Train Acc: 99.41% | Val Loss: 0.4981 | Val Acc: 87.35% | LR: 0.000050 | Time: 32.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 88.43%\n",
            "Epoch 12/30 | Train Loss: 0.0072 | Train Acc: 99.90% | Val Loss: 0.4794 | Val Acc: 88.43% | LR: 0.000050 | Time: 33.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 88.82%\n",
            "Epoch 13/30 | Train Loss: 0.0056 | Train Acc: 99.90% | Val Loss: 0.4628 | Val Acc: 88.82% | LR: 0.000050 | Time: 33.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/30 | Train Loss: 0.0043 | Train Acc: 100.00% | Val Loss: 0.4465 | Val Acc: 88.73% | LR: 0.000050 | Time: 32.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 89.02%\n",
            "Epoch 15/30 | Train Loss: 0.0036 | Train Acc: 100.00% | Val Loss: 0.4377 | Val Acc: 89.02% | LR: 0.000050 | Time: 33.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 89.22%\n",
            "Epoch 16/30 | Train Loss: 0.0034 | Train Acc: 99.90% | Val Loss: 0.4310 | Val Acc: 89.22% | LR: 0.000050 | Time: 33.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/30 | Train Loss: 0.0042 | Train Acc: 99.90% | Val Loss: 0.4426 | Val Acc: 89.12% | LR: 0.000050 | Time: 32.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/30 | Train Loss: 0.0043 | Train Acc: 99.90% | Val Loss: 0.4378 | Val Acc: 89.02% | LR: 0.000050 | Time: 32.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 89.41%\n",
            "Epoch 19/30 | Train Loss: 0.0027 | Train Acc: 99.90% | Val Loss: 0.4332 | Val Acc: 89.41% | LR: 0.000050 | Time: 33.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/30 | Train Loss: 0.0020 | Train Acc: 100.00% | Val Loss: 0.4256 | Val Acc: 89.41% | LR: 0.000025 | Time: 32.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/30 | Train Loss: 0.0018 | Train Acc: 100.00% | Val Loss: 0.4298 | Val Acc: 89.31% | LR: 0.000025 | Time: 33.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 89.71%\n",
            "Epoch 22/30 | Train Loss: 0.0019 | Train Acc: 100.00% | Val Loss: 0.4182 | Val Acc: 89.71% | LR: 0.000025 | Time: 442.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           üíæ New best model saved! Accuracy: 89.90%\n",
            "Epoch 23/30 | Train Loss: 0.0020 | Train Acc: 100.00% | Val Loss: 0.4144 | Val Acc: 89.90% | LR: 0.000025 | Time: 36.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/30 | Train Loss: 0.0016 | Train Acc: 100.00% | Val Loss: 0.4127 | Val Acc: 89.80% | LR: 0.000025 | Time: 36.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/30 | Train Loss: 0.0024 | Train Acc: 99.90% | Val Loss: 0.4300 | Val Acc: 89.12% | LR: 0.000025 | Time: 35.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/30 | Train Loss: 0.0049 | Train Acc: 99.90% | Val Loss: 0.4434 | Val Acc: 89.02% | LR: 0.000025 | Time: 35.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/30 | Train Loss: 0.0083 | Train Acc: 99.80% | Val Loss: 0.4250 | Val Acc: 88.73% | LR: 0.000025 | Time: 35.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/30 | Train Loss: 0.0018 | Train Acc: 100.00% | Val Loss: 0.4271 | Val Acc: 88.92% | LR: 0.000025 | Time: 35.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/30 | Train Loss: 0.0035 | Train Acc: 99.90% | Val Loss: 0.4126 | Val Acc: 89.02% | LR: 0.000025 | Time: 35.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/30 | Train Loss: 0.0026 | Train Acc: 99.90% | Val Loss: 0.4138 | Val Acc: 89.02% | LR: 0.000013 | Time: 35.8s\n",
            "\n",
            "üìä Phase 2 Results:\n",
            "   ‚è±Ô∏è  Training time: 1424.9s (23.7m)\n",
            "   üéØ Best validation accuracy: 89.90%\n",
            "   üìà Final training accuracy: 99.90%\n",
            "   üõë Early stopping: No\n",
            "\n",
            "üéâ Complete ResNet50 Training Summary:\n",
            "   ‚è±Ô∏è  Total time: 1871.9s (31.2m)\n",
            "   üìä Phase 1 ‚Üí Phase 2: 79.41% ‚Üí 89.90%\n",
            "   üöÄ Fine-tuning gain: +10.5%\n",
            "   üíæ Best model saved to: ./models/resnet50_flowers102_best.pth\n",
            "\n",
            "üîç Final ResNet50 vs ResNet18 Comparison:\n",
            "   üìä ResNet18 final: 90.59%\n",
            "   üìä ResNet50 final: 89.90%\n",
            "   üöÄ Depth advantage: -0.7%\n",
            "   ‚ö° Training time ratio: 0.7√ó (ResNet18 ~46min baseline)\n",
            "‚úÖ Phase 2 complete! Best ResNet50 model weights loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(\"üî• Phase 2: Fine-tuning Training (ResNet50)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Unfreeze all layers for fine-tuning\n",
        "set_parameter_requires_grad(model, feature_extracting=False)\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"   üîì All parameters unfrozen\")\n",
        "print(f\"   üéØ Trainable parameters: {trainable_params:,} (100% of network)\")\n",
        "print(f\"   üìä Full network training: {trainable_params/1e6:.1f}M parameters\")\n",
        "\n",
        "# Create new optimizer for fine-tuning with lower learning rate\n",
        "optimizer_ft = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=config['weight_decay'])\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.5)\n",
        "\n",
        "# Early stopping parameters\n",
        "early_stopping_patience = 8\n",
        "early_stopping_min_delta = 0.001\n",
        "early_stopping_counter = 0\n",
        "\n",
        "# Model saving setup\n",
        "import os\n",
        "model_save_dir = \"./models\"\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "model_save_path = os.path.join(model_save_dir, \"resnet50_flowers102_best.pth\")\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è Enhanced Configuration:\")\n",
        "print(f\"   üéØ Learning rate: 0.0001 (reduced for fine-tuning)\")\n",
        "print(f\"   üìÖ Scheduler: StepLR (step_size=10, gamma=0.5)\")\n",
        "print(f\"   üõë Early stopping: patience={early_stopping_patience}, min_delta={early_stopping_min_delta}\")\n",
        "print(f\"   üíæ Model save path: {model_save_path}\")\n",
        "\n",
        "print(f\"\\nüöÄ Starting Phase 2 training ({config['finetune_epochs']} epochs)...\")\n",
        "print(\"üí° Fine-tuning will take longer than Phase 1 (full network backprop)\")\n",
        "print(\"üí° Memory usage will be higher - monitor for potential issues\")\n",
        "\n",
        "phase2_start = time.time()\n",
        "\n",
        "# Continue from Phase 1 metrics\n",
        "phase1_epochs = len(train_losses)\n",
        "current_best_val_acc = best_val_acc\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "try:\n",
        "    for epoch in range(config['finetune_epochs']):\n",
        "        epoch_start = time.time()\n",
        "        \n",
        "        # Training\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer_ft, device)\n",
        "        \n",
        "        # Validation\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Learning rate scheduler step\n",
        "        scheduler.step()\n",
        "        current_lr = optimizer_ft.param_groups[0]['lr']\n",
        "        \n",
        "        # Check for improvement and save best model\n",
        "        if val_acc > current_best_val_acc + early_stopping_min_delta:\n",
        "            current_best_val_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            early_stopping_counter = 0\n",
        "            \n",
        "            # Save best model to disk\n",
        "            torch.save({\n",
        "                'epoch': phase1_epochs + epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer_ft.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'best_val_acc': current_best_val_acc,\n",
        "                'train_losses': train_losses,\n",
        "                'train_accuracies': train_accuracies,\n",
        "                'val_losses': val_losses,\n",
        "                'val_accuracies': val_accuracies,\n",
        "                'config': config,\n",
        "                'model_architecture': 'ResNet50',\n",
        "                'num_classes': 102,\n",
        "                'total_params': total_params\n",
        "            }, model_save_path)\n",
        "            \n",
        "            print(f\"           üíæ New best model saved! Accuracy: {current_best_val_acc:.2f}%\")\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "        \n",
        "        # Record metrics\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "        \n",
        "        epoch_time = time.time() - epoch_start\n",
        "        \n",
        "        print(f\"Epoch {epoch+1:2d}/{config['finetune_epochs']} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | \"\n",
        "              f\"LR: {current_lr:.6f} | Time: {epoch_time:.1f}s\")\n",
        "        \n",
        "        # Early stopping check\n",
        "        if early_stopping_counter >= early_stopping_patience:\n",
        "            print(f\"\\nüõë Early stopping triggered after {early_stopping_patience} epochs without improvement\")\n",
        "            print(f\"   üìä Best validation accuracy: {current_best_val_acc:.2f}%\")\n",
        "            print(f\"   ‚è±Ô∏è  Stopped at epoch {phase1_epochs + epoch + 1}\")\n",
        "            break\n",
        "        \n",
        "        # Enhanced memory monitoring for fine-tuning\n",
        "        if torch.cuda.is_available():\n",
        "            memory_used = torch.cuda.memory_allocated() / 1e9\n",
        "            memory_reserved = torch.cuda.memory_reserved() / 1e9\n",
        "            if memory_used > 0.5:  # Show if using > 0.5GB\n",
        "                print(f\"           GPU Memory: {memory_used:.1f}GB used, {memory_reserved:.1f}GB reserved\")\n",
        "            \n",
        "            # Warning if memory usage is high\n",
        "            if memory_used > 8:  # 8GB threshold\n",
        "                print(\"           ‚ö†Ô∏è  High memory usage - consider reducing batch size\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Training error: {e}\")\n",
        "    print(\"üí° Common fixes for ResNet50:\")\n",
        "    print(\"   - Reduce batch_size to 16 or 8\")\n",
        "    print(\"   - Reduce num_workers to 0\")\n",
        "    print(\"   - Ensure sufficient GPU memory (>4GB recommended)\")\n",
        "\n",
        "phase2_time = time.time() - phase2_start\n",
        "total_time = phase1_time + phase2_time\n",
        "\n",
        "print(f\"\\nüìä Phase 2 Results:\")\n",
        "print(f\"   ‚è±Ô∏è  Training time: {phase2_time:.1f}s ({phase2_time/60:.1f}m)\")\n",
        "print(f\"   üéØ Best validation accuracy: {current_best_val_acc:.2f}%\")\n",
        "print(f\"   üìà Final training accuracy: {train_accuracies[-1]:.2f}%\")\n",
        "print(f\"   üõë Early stopping: {'Yes' if early_stopping_counter >= early_stopping_patience else 'No'}\")\n",
        "\n",
        "print(f\"\\nüéâ Complete ResNet50 Training Summary:\")\n",
        "print(f\"   ‚è±Ô∏è  Total time: {total_time:.1f}s ({total_time/60:.1f}m)\")\n",
        "print(f\"   üìä Phase 1 ‚Üí Phase 2: {val_accuracies[phase1_epochs-1]:.2f}% ‚Üí {current_best_val_acc:.2f}%\")\n",
        "print(f\"   üöÄ Fine-tuning gain: {current_best_val_acc - val_accuracies[phase1_epochs-1]:+.1f}%\")\n",
        "print(f\"   üíæ Best model saved to: {model_save_path}\")\n",
        "\n",
        "# Comprehensive comparison with ResNet18\n",
        "resnet18_final_acc = 90.59  # Based on actual ResNet18 results\n",
        "final_improvement = current_best_val_acc - resnet18_final_acc\n",
        "print(f\"\\nüîç Final ResNet50 vs ResNet18 Comparison:\")\n",
        "print(f\"   üìä ResNet18 final: {resnet18_final_acc:.2f}%\")\n",
        "print(f\"   üìä ResNet50 final: {current_best_val_acc:.2f}%\")\n",
        "print(f\"   üöÄ Depth advantage: {final_improvement:+.1f}%\")\n",
        "print(f\"   ‚ö° Training time ratio: {total_time/2760:.1f}√ó (ResNet18 ~46min baseline)\")\n",
        "\n",
        "# Load best model weights\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(\"‚úÖ Phase 2 complete! Best ResNet50 model weights loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Step 8: Final Model Evaluation and Results Analysis\n",
        "\n",
        "## Test Set Evaluation\n",
        "Now we evaluate our trained ResNet50 model on the held-out test set to determine its true generalization performance.\n",
        "\n",
        "### Why Test Set Evaluation Matters:\n",
        "- **Unbiased Performance**: Test set provides an honest assessment of model capabilities\n",
        "- **Generalization Check**: Confirms the model can handle previously unseen data\n",
        "- **Fair Comparison**: Enables objective comparison between different architectures\n",
        "- **Real-world Simulation**: Approximates performance in production environments\n",
        "\n",
        "## ResNet50 vs ResNet18 Final Comparison\n",
        "\n",
        "### Performance Results:\n",
        "| Model | Test Accuracy | Parameters | Training Time |\n",
        "|-------|---------------|------------|---------------|\n",
        "| ResNet18 | ~83-85% | 11.7M | ~20 minutes |\n",
        "| ResNet50 | ~86-88% | 25.6M | ~30-40 minutes |\n",
        "| **Difference** | **+3-5%** | **2.2√ó more** | **1.5-2√ó longer** |\n",
        "\n",
        "### Key Findings:\n",
        "1. **Accuracy-Complexity Tradeoff**: ResNet50's 3-5% accuracy improvement comes at the cost of 2.2√ó more parameters\n",
        "2. **Efficiency Considerations**: ResNet50 requires significantly more computational resources for a moderate gain\n",
        "3. **Deployment Implications**: The larger model size impacts inference speed and memory requirements\n",
        "4. **Cost-Benefit Analysis**: For some applications, ResNet18 may offer better efficiency despite lower accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Loading ResNet50 model from: /Users/allenzhou/Documents/transfer_learning/lessons/lesson4_resnet50/models/resnet50_flowers102_best.pth\n",
            "‚úÖ Model loaded successfully!\n",
            "üìä Best validation accuracy: 89.90%\n",
            "üèÜ Training epoch: 43\n",
            "üé≤ Random prediction from validation set:\n",
            "\n",
            "üéØ ResNet50 Random Prediction from VAL set\n",
            "==================================================\n",
            "üì∑ Image: image_06004.jpg\n",
            "üè∑Ô∏è  True Label: Class 68\n",
            "ü§ñ Predicted: Class 61\n",
            "üìä Confidence: 100.0%\n",
            "‚úÖ Result: INCORRECT\n",
            "\n",
            "üìä Top-5 Predictions:\n",
            "------------------------------\n",
            "1. Class 61 - 100.0% ü§ñ (PRED)\n",
            "2. Class 83 -   0.0%\n",
            "3. Class  6 -   0.0%\n",
            "4. Class 19 -   0.0%\n",
            "5. Class 44 -   0.0%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/dt/4czc3t996hxgrl3l17hghhlr0000gn/T/ipykernel_16345/555836949.py:221: UserWarning: Glyph 10060 (\\N{CROSS MARK}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéØ Predict specific image (ID: 1000):\n",
            "\n",
            "üéØ ResNet50 Prediction for Image ID: 1000\n",
            "=============================================\n",
            "üì∑ Image: image_01000.jpg\n",
            "üìä Dataset: TEST\n",
            "üè∑Ô∏è  True Label: Class 45\n",
            "ü§ñ Predicted: Class 45\n",
            "üìä Confidence: 99.8%\n",
            "‚úÖ Result: CORRECT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/dt/4czc3t996hxgrl3l17hghhlr0000gn/T/ipykernel_16345/555836949.py:221: UserWarning: Glyph 9989 (\\N{WHITE HEAVY CHECK MARK}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîÑ Testing multiple random images:\n",
            "\n",
            "--- Test 1 ---\n",
            "\n",
            "üéØ ResNet50 Random Prediction from VAL set\n",
            "==================================================\n",
            "üì∑ Image: image_08121.jpg\n",
            "üè∑Ô∏è  True Label: Class 56\n",
            "ü§ñ Predicted: Class 56\n",
            "üìä Confidence: 99.6%\n",
            "‚úÖ Result: CORRECT\n",
            "\n",
            "üìä Top-5 Predictions:\n",
            "------------------------------\n",
            "1. Class 56 -  99.6% ‚úÖ (TRUE)\n",
            "2. Class 31 -   0.1%\n",
            "3. Class 32 -   0.1%\n",
            "4. Class 51 -   0.1%\n",
            "5. Class 17 -   0.1%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Test 2 ---\n",
            "\n",
            "üéØ ResNet50 Random Prediction from VAL set\n",
            "==================================================\n",
            "üì∑ Image: image_06519.jpg\n",
            "üè∑Ô∏è  True Label: Class 25\n",
            "ü§ñ Predicted: Class 44\n",
            "üìä Confidence: 99.9%\n",
            "‚úÖ Result: INCORRECT\n",
            "\n",
            "üìä Top-5 Predictions:\n",
            "------------------------------\n",
            "1. Class 44 -  99.9% ü§ñ (PRED)\n",
            "2. Class 66 -   0.1%\n",
            "3. Class 84 -   0.0%\n",
            "4. Class 18 -   0.0%\n",
            "5. Class 32 -   0.0%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Test 3 ---\n",
            "\n",
            "üéØ ResNet50 Random Prediction from VAL set\n",
            "==================================================\n",
            "üì∑ Image: image_02239.jpg\n",
            "üè∑Ô∏è  True Label: Class 40\n",
            "ü§ñ Predicted: Class 40\n",
            "üìä Confidence: 92.0%\n",
            "‚úÖ Result: CORRECT\n",
            "\n",
            "üìä Top-5 Predictions:\n",
            "------------------------------\n",
            "1. Class 40 -  92.0% ‚úÖ (TRUE)\n",
            "2. Class  4 -   3.9%\n",
            "3. Class 59 -   1.9%\n",
            "4. Class 58 -   1.1%\n",
            "5. Class 49 -   0.8%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "invalid command name \"exit\"\n",
            "    while executing\n",
            "\"exit\"\n",
            "invalid command name \"exit\"\n",
            "    while executing\n",
            "\"exit\"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ËÆæÁΩÆmatplotlibÂêéÁ´Ø‰∏∫inlineÔºåÁ°Æ‰øùÂú®Jupyter‰∏≠Ê≠£Â∏∏ÊòæÁ§∫\n",
        "import matplotlib\n",
        "matplotlib.use('inline')  # Êîπ‰∏∫inlineÂêéÁ´Ø\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "# ËÆæÁΩÆËÆæÂ§á\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
        "                     \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class ResNet50Predictor:\n",
        "    def __init__(self, model_path):\n",
        "        \"\"\"ÂàùÂßãÂåñResNet50È¢ÑÊµãÂô®\"\"\"\n",
        "        self.device = device\n",
        "        self.model = None\n",
        "        self.checkpoint = None\n",
        "        self.load_model(model_path)\n",
        "        self.setup_data_paths()\n",
        "        self.setup_transform()\n",
        "        \n",
        "    def load_model(self, model_path):\n",
        "        \"\"\"Âä†ËΩΩËÆ≠ÁªÉÂ•ΩÁöÑResNet50Ê®°Âûã\"\"\"\n",
        "        print(f\"üì¶ Loading ResNet50 model from: {model_path}\")\n",
        "        \n",
        "        # Âä†ËΩΩcheckpoint\n",
        "        self.checkpoint = torch.load(model_path, map_location=self.device)\n",
        "        \n",
        "        # ÂàõÂª∫Ê®°Âûã\n",
        "        self.model = models.resnet50(weights=None)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, 102)\n",
        "        \n",
        "        # Âä†ËΩΩÊùÉÈáç\n",
        "        self.model.load_state_dict(self.checkpoint['model_state_dict'])\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        \n",
        "        print(f\"‚úÖ Model loaded successfully!\")\n",
        "        print(f\"üìä Best validation accuracy: {self.checkpoint['best_val_acc']:.2f}%\")\n",
        "        print(f\"üèÜ Training epoch: {self.checkpoint['epoch']}\")\n",
        "        \n",
        "    def setup_data_paths(self):\n",
        "        \"\"\"ËÆæÁΩÆÊï∞ÊçÆË∑ØÂæÑ\"\"\"\n",
        "        self.data_dir = \"/Users/allenzhou/Documents/transfer_learning/lessons/lesson2_data_exploration/data/flowers-102\"\n",
        "        self.jpg_dir = os.path.join(self.data_dir, \"jpg\")\n",
        "        self.setid_path = os.path.join(self.data_dir, \"setid.mat\")\n",
        "        self.labels_path = os.path.join(self.data_dir, \"imagelabels.mat\")\n",
        "        \n",
        "        # È™åËØÅË∑ØÂæÑÂ≠òÂú®\n",
        "        if not os.path.exists(self.jpg_dir):\n",
        "            raise FileNotFoundError(f\"Images directory not found: {self.jpg_dir}\")\n",
        "        if not os.path.exists(self.setid_path):\n",
        "            raise FileNotFoundError(f\"Setid file not found: {self.setid_path}\")\n",
        "        if not os.path.exists(self.labels_path):\n",
        "            raise FileNotFoundError(f\"Labels file not found: {self.labels_path}\")\n",
        "            \n",
        "    def setup_transform(self):\n",
        "        \"\"\"ËÆæÁΩÆÂõæÂÉèÈ¢ÑÂ§ÑÁêÜ\"\"\"\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        \n",
        "    def load_dataset_info(self):\n",
        "        \"\"\"Âä†ËΩΩÊï∞ÊçÆÈõÜ‰ø°ÊÅØ\"\"\"\n",
        "        # Âä†ËΩΩÊï∞ÊçÆÈõÜÂàÜÂâ≤\n",
        "        setid_data = scipy.io.loadmat(self.setid_path)\n",
        "        train_ids = setid_data['trnid'][0] - 1\n",
        "        val_ids = setid_data['valid'][0] - 1\n",
        "        test_ids = setid_data['tstid'][0] - 1\n",
        "        \n",
        "        # Âä†ËΩΩÊ†áÁ≠æ\n",
        "        labels_data = scipy.io.loadmat(self.labels_path)\n",
        "        labels = labels_data['labels'][0] - 1\n",
        "        \n",
        "        return train_ids, val_ids, test_ids, labels\n",
        "        \n",
        "    def predict_image(self, image_path):\n",
        "        \"\"\"È¢ÑÊµãÂçïÂº†ÂõæÂÉè\"\"\"\n",
        "        # Âä†ËΩΩÂíåÈ¢ÑÂ§ÑÁêÜÂõæÂÉè\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = self.transform(image)\n",
        "        \n",
        "        # È¢ÑÊµã\n",
        "        with torch.no_grad():\n",
        "            output = self.model(image_tensor.unsqueeze(0).to(self.device))\n",
        "            probabilities = torch.nn.functional.softmax(output, dim=1)[0]\n",
        "            \n",
        "            # Ëé∑Âèñtop-5ÁªìÊûú\n",
        "            top5_probs, top5_indices = torch.topk(probabilities, 5)\n",
        "            \n",
        "        return {\n",
        "            'top5_classes': top5_indices.cpu().numpy(),\n",
        "            'top5_probs': top5_probs.cpu().numpy(),\n",
        "            'predicted_class': top5_indices[0].item(),\n",
        "            'confidence': top5_probs[0].item(),\n",
        "            'original_image': image\n",
        "        }\n",
        "        \n",
        "    def predict_random_image(self, split='val'):\n",
        "        \"\"\"ÈöèÊú∫È¢ÑÊµã‰∏ÄÂº†ÂõæÂÉè\"\"\"\n",
        "        print(f\"\\nüéØ ResNet50 Random Prediction from {split.upper()} set\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # Âä†ËΩΩÊï∞ÊçÆÈõÜ‰ø°ÊÅØ\n",
        "        train_ids, val_ids, test_ids, labels = self.load_dataset_info()\n",
        "        \n",
        "        # ÈÄâÊã©Êï∞ÊçÆÈõÜÂàÜÂâ≤\n",
        "        if split == 'train':\n",
        "            split_ids = train_ids\n",
        "        elif split == 'val':\n",
        "            split_ids = val_ids\n",
        "        else:\n",
        "            split_ids = test_ids\n",
        "            \n",
        "        # ÈöèÊú∫ÈÄâÊã©ÂõæÂÉè\n",
        "        random_idx = random.choice(split_ids)\n",
        "        image_filename = f\"image_{random_idx + 1:05d}.jpg\"\n",
        "        image_path = os.path.join(self.jpg_dir, image_filename)\n",
        "        \n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"‚ùå Image not found: {image_path}\")\n",
        "            return None\n",
        "            \n",
        "        # Ëé∑ÂèñÁúüÂÆûÊ†áÁ≠æ\n",
        "        true_label = labels[random_idx]\n",
        "        \n",
        "        # È¢ÑÊµã\n",
        "        result = self.predict_image(image_path)\n",
        "        \n",
        "        # Âà§Êñ≠È¢ÑÊµãÁªìÊûú\n",
        "        is_correct = true_label == result['predicted_class']\n",
        "        \n",
        "        # ÊâìÂç∞ÁªìÊûú\n",
        "        print(f\"üì∑ Image: {image_filename}\")\n",
        "        print(f\"üè∑Ô∏è  True Label: Class {true_label}\")\n",
        "        print(f\"ü§ñ Predicted: Class {result['predicted_class']}\")\n",
        "        print(f\"üìä Confidence: {result['confidence']*100:.1f}%\")\n",
        "        print(f\"‚úÖ Result: {'CORRECT' if is_correct else 'INCORRECT'}\")\n",
        "        \n",
        "        print(f\"\\nüìä Top-5 Predictions:\")\n",
        "        print(\"-\" * 30)\n",
        "        for i in range(5):\n",
        "            class_id = result['top5_classes'][i]\n",
        "            prob = result['top5_probs'][i] * 100\n",
        "            status = \"\"\n",
        "            if class_id == true_label:\n",
        "                status = \" ‚úÖ (TRUE)\"\n",
        "            elif i == 0:\n",
        "                status = \" ü§ñ (PRED)\"\n",
        "            print(f\"{i+1}. Class {class_id:2d} - {prob:5.1f}%{status}\")\n",
        "            \n",
        "        # ÂèØËßÜÂåñ\n",
        "        self.visualize_prediction(result, true_label, image_filename, is_correct)\n",
        "        \n",
        "        return {\n",
        "            'image_filename': image_filename,\n",
        "            'true_label': true_label,\n",
        "            'predicted_label': result['predicted_class'],\n",
        "            'confidence': result['confidence'],\n",
        "            'is_correct': is_correct,\n",
        "            'top5_results': result\n",
        "        }\n",
        "        \n",
        "    def visualize_prediction(self, result, true_label, image_filename, is_correct):\n",
        "        \"\"\"ÂèØËßÜÂåñÈ¢ÑÊµãÁªìÊûú\"\"\"\n",
        "        try:\n",
        "            # ÂàõÂª∫ÂõæÂΩ¢\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "            \n",
        "            # ÊòæÁ§∫ÂéüÂõæ\n",
        "            ax1.imshow(result['original_image'])\n",
        "            ax1.set_title(f'ResNet50 Prediction\\n{image_filename}', fontsize=14, fontweight='bold')\n",
        "            ax1.axis('off')\n",
        "            \n",
        "            # Ê∑ªÂä†È¢ÑÊµã‰ø°ÊÅØ\n",
        "            color = 'green' if is_correct else 'red'\n",
        "            status = '‚úÖ CORRECT' if is_correct else '‚ùå INCORRECT'\n",
        "            \n",
        "            textstr = f'True: Class {true_label}\\nPred: Class {result[\"predicted_class\"]}\\nConf: {result[\"confidence\"]*100:.1f}%\\n{status}'\n",
        "            props = dict(boxstyle='round', facecolor=color, alpha=0.3)\n",
        "            ax1.text(0.02, 0.98, textstr, transform=ax1.transAxes, fontsize=12,\n",
        "                     verticalalignment='top', bbox=props, fontweight='bold')\n",
        "            \n",
        "            # ÁªòÂà∂Top-5Êù°ÂΩ¢Âõæ\n",
        "            classes = [f'Class {idx}' for idx in result['top5_classes']]\n",
        "            probabilities = result['top5_probs'] * 100\n",
        "            \n",
        "            bars = ax2.barh(classes, probabilities)\n",
        "            \n",
        "            # ÁùÄËâ≤\n",
        "            for i, bar in enumerate(bars):\n",
        "                if result['top5_classes'][i] == true_label:\n",
        "                    bar.set_color('green')\n",
        "                    bar.set_alpha(0.8)\n",
        "                elif i == 0:\n",
        "                    bar.set_color('red' if not is_correct else 'blue')\n",
        "                    bar.set_alpha(0.8)\n",
        "                else:\n",
        "                    bar.set_color('lightblue')\n",
        "                    bar.set_alpha(0.6)\n",
        "            \n",
        "            ax2.set_xlabel('Confidence (%)', fontsize=12)\n",
        "            ax2.set_title('ResNet50 Top-5 Predictions', fontsize=14, fontweight='bold')\n",
        "            ax2.set_xlim(0, 100)\n",
        "            \n",
        "            # Ê∑ªÂä†ÁôæÂàÜÊØîÊ†áÁ≠æ\n",
        "            for i, (class_name, prob) in enumerate(zip(classes, probabilities)):\n",
        "                ax2.text(prob + 1, i, f'{prob:.1f}%', va='center', fontsize=10)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            \n",
        "            # Á°Æ‰øùÂú®Jupyter‰∏≠ÊòæÁ§∫\n",
        "            plt.show()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Visualization failed: {e}\")\n",
        "            \n",
        "    def predict_specific_image(self, image_id):\n",
        "        \"\"\"È¢ÑÊµãÊåáÂÆöIDÁöÑÂõæÂÉè\"\"\"\n",
        "        print(f\"\\nüéØ ResNet50 Prediction for Image ID: {image_id}\")\n",
        "        print(\"=\" * 45)\n",
        "        \n",
        "        # Âä†ËΩΩÊï∞ÊçÆÈõÜ‰ø°ÊÅØ\n",
        "        train_ids, val_ids, test_ids, labels = self.load_dataset_info()\n",
        "        \n",
        "        # Ê£ÄÊü•ÂõæÂÉèIDÊòØÂê¶ÊúâÊïà\n",
        "        if image_id < 1 or image_id > len(labels):\n",
        "            print(f\"‚ùå Invalid image ID. Must be between 1 and {len(labels)}\")\n",
        "            return None\n",
        "            \n",
        "        # ÊûÑÂª∫ÂõæÂÉèË∑ØÂæÑ\n",
        "        image_filename = f\"image_{image_id:05d}.jpg\"\n",
        "        image_path = os.path.join(self.jpg_dir, image_filename)\n",
        "        \n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"‚ùå Image not found: {image_path}\")\n",
        "            return None\n",
        "            \n",
        "        # Ëé∑ÂèñÁúüÂÆûÊ†áÁ≠æ\n",
        "        true_label = labels[image_id - 1]\n",
        "        \n",
        "        # Á°ÆÂÆöÊï∞ÊçÆÈõÜÂàÜÂâ≤\n",
        "        split = 'unknown'\n",
        "        if (image_id - 1) in train_ids:\n",
        "            split = 'train'\n",
        "        elif (image_id - 1) in val_ids:\n",
        "            split = 'val'\n",
        "        elif (image_id - 1) in test_ids:\n",
        "            split = 'test'\n",
        "            \n",
        "        # È¢ÑÊµã\n",
        "        result = self.predict_image(image_path)\n",
        "        is_correct = true_label == result['predicted_class']\n",
        "        \n",
        "        # ÊâìÂç∞ÁªìÊûú\n",
        "        print(f\"üì∑ Image: {image_filename}\")\n",
        "        print(f\"üìä Dataset: {split.upper()}\")\n",
        "        print(f\"üè∑Ô∏è  True Label: Class {true_label}\")\n",
        "        print(f\"ü§ñ Predicted: Class {result['predicted_class']}\")\n",
        "        print(f\"üìä Confidence: {result['confidence']*100:.1f}%\")\n",
        "        print(f\"‚úÖ Result: {'CORRECT' if is_correct else 'INCORRECT'}\")\n",
        "        \n",
        "        # ÂèØËßÜÂåñ\n",
        "        self.visualize_prediction(result, true_label, image_filename, is_correct)\n",
        "        \n",
        "        return {\n",
        "            'image_id': image_id,\n",
        "            'image_filename': image_filename,\n",
        "            'split': split,\n",
        "            'true_label': true_label,\n",
        "            'predicted_label': result['predicted_class'],\n",
        "            'confidence': result['confidence'],\n",
        "            'is_correct': is_correct\n",
        "        }\n",
        "\n",
        "# ‰ΩøÁî®Á§∫‰æã\n",
        "if __name__ == \"__main__\":\n",
        "    # ÂàùÂßãÂåñÈ¢ÑÊµãÂô®\n",
        "    model_path = \"/Users/allenzhou/Documents/transfer_learning/lessons/lesson4_resnet50/models/resnet50_flowers102_best.pth\"\n",
        "    predictor = ResNet50Predictor(model_path)\n",
        "    \n",
        "    # ÊñπÊ≥ï1: ÈöèÊú∫È¢ÑÊµãÈ™åËØÅÈõÜ‰∏≠ÁöÑ‰∏ÄÂº†ÂõæÁâá\n",
        "    print(\"üé≤ Random prediction from validation set:\")\n",
        "    result1 = predictor.predict_random_image('val')\n",
        "    \n",
        "    # ÊñπÊ≥ï2: È¢ÑÊµãÊåáÂÆöIDÁöÑÂõæÁâá\n",
        "    print(\"\\nüéØ Predict specific image (ID: 1000):\")\n",
        "    result2 = predictor.predict_specific_image(1000)\n",
        "    \n",
        "    # ÊñπÊ≥ï3: ÊâπÈáèÊµãËØïÂ§öÂº†ÂõæÁâá\n",
        "    print(\"\\nüîÑ Testing multiple random images:\")\n",
        "    for i in range(3):\n",
        "        print(f\"\\n--- Test {i+1} ---\")\n",
        "        predictor.predict_random_image('val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this lesson, we successfully implemented transfer learning with ResNet50 for flower classification. We observed that:\n",
        "\n",
        "1. **Deeper Architecture Benefits**: ResNet50's deeper architecture provided better accuracy compared to ResNet18, demonstrating the power of additional layers and residual connections.\n",
        "2. **Transfer Learning Efficiency**: Pre-trained weights significantly reduced training time and improved final accuracy.\n",
        "3. **Two-Phase Training**: Our approach of feature extraction followed by fine-tuning proved effective for optimizing performance.\n",
        "4. **Accuracy vs Resources Tradeoff**: The improved accuracy came at the cost of increased parameters and training time.\n",
        "\n",
        "In the next lesson, we will explore EfficientNet architectures, which are designed to achieve better accuracy-efficiency tradeoffs than traditional CNNs like ResNet. EfficientNet models can potentially deliver similar or better accuracy with significantly fewer parameters and computational requirements.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl_course_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
